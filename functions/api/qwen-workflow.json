{
  "1": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "input.png"
    },
    "_meta": {
      "title": "Load Image"
    }
  },
  "2": {
    "class_type": "CLIPLoader",
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "3": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "_meta": {
      "title": "Load VAE"
    }
  },
  "4": {
    "class_type": "TextEncodeQwenImageEditPlus",
    "inputs": {
      "clip": [
        "2",
        0
      ],
      "prompt": "",
      "vae": [
        "3",
        0
      ],
      "image1": [
        "16",
        0
      ],
      "image2": [
        "25",
        0
      ]
    },
    "_meta": {
      "title": "Prompt"
    }
  },
  "5": {
    "class_type": "UnetLoaderGGUF",
    "inputs": {
      "unet_name": "qwen-image-edit-2511-Q4_K_M.gguf"
    },
    "_meta": {
      "title": "Load UNet GGUF"
    }
  },
  "6": {
    "class_type": "ModelSamplingAuraFlow",
    "inputs": {
      "model": [
        "23",
        0
      ],
      "shift": 3.1
    },
    "_meta": {
      "title": "AuraFlow Sampling"
    }
  },
  "7": {
    "class_type": "CFGNorm",
    "inputs": {
      "model": [
        "6",
        0
      ],
      "strength": 1
    },
    "_meta": {
      "title": "CFG Norm"
    }
  },
  "9": {
    "class_type": "VAEEncode",
    "inputs": {
      "pixels": [
        "16",
        0
      ],
      "vae": [
        "3",
        0
      ]
    },
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "10": {
    "class_type": "KSampler",
    "inputs": {
      "model": [
        "7",
        0
      ],
      "seed": 1234,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "positive": [
        "15",
        0
      ],
      "negative": [
        "14",
        0
      ],
      "latent_image": [
        "9",
        0
      ],
      "denoise": 1
    },
    "_meta": {
      "title": "KSampler"
    }
  },
  "11": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": [
        "10",
        0
      ],
      "vae": [
        "3",
        0
      ]
    },
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "12": {
    "class_type": "SaveImage",
    "inputs": {
      "images": [
        "11",
        0
      ],
      "filename_prefix": "Qwen_Edit_2511"
    },
    "_meta": {
      "title": "Save Image"
    }
  },
  "13": {
    "class_type": "TextEncodeQwenImageEditPlus",
    "inputs": {
      "clip": [
        "2",
        0
      ],
      "prompt": "",
      "vae": [
        "3",
        0
      ],
      "image1": [
        "16",
        0
      ],
      "image2": [
        "25",
        0
      ]
    },
    "_meta": {
      "title": "Negative Prompt"
    }
  },
  "14": {
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "inputs": {
      "conditioning": [
        "13",
        0
      ],
      "reference_latents_method": "index_timestep_zero"
    },
    "_meta": {
      "title": "Reference Method (Negative)"
    }
  },
  "15": {
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "inputs": {
      "conditioning": [
        "4",
        0
      ],
      "reference_latents_method": "index_timestep_zero"
    },
    "_meta": {
      "title": "Reference Method (Positive)"
    }
  },
  "16": {
    "class_type": "ResizeAndPadImage",
    "inputs": {
      "image": [
        "1",
        0
      ],
      "target_width": 1024,
      "target_height": 1024,
      "padding_color": "black",
      "interpolation": "lanczos"
    },
    "_meta": {
      "title": "Resize + Pad Source"
    }
  },
  "17": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "5",
        0
      ],
      "lora_name": "Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors",
      "strength_model": 1
    },
    "_meta": {
      "title": "Apply Lightning LoRA"
    }
  },
  "18": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "17",
        0
      ],
      "lora_name": "Qwen_Snofs_1_3.safetensors",
      "strength_model": 1
    },
    "_meta": {
      "title": "Apply Snofs LoRA"
    }
  },
  "19": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "18",
        0
      ],
      "lora_name": "qwen-edit-skin_1.1_000002750.safetensors",
      "strength_model": 1.0
    },
    "_meta": {
      "title": "Apply Skin LoRA"
    }
  },
  "22": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "19",
        0
      ],
      "lora_name": "NSFW Female Enhancer Qwen V0.3.safetensors",
      "strength_model": 1
    },
    "_meta": {
      "title": "Apply NSFW Enhancer LoRA"
    }
  },
  "23": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "model": [
        "22",
        0
      ],
      "lora_name": "qwen-image-edit-2511-multiple-angles-lora.safetensors",
      "strength_model": 1
    },
    "_meta": {
      "title": "Apply Multiangle LoRA"
    }
  },
  "24": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "sub.png"
    },
    "_meta": {
      "title": "Load Sub Image"
    }
  },
  "25": {
    "class_type": "ResizeAndPadImage",
    "inputs": {
      "image": [
        "24",
        0
      ],
      "target_width": 1024,
      "target_height": 1024,
      "padding_color": "black",
      "interpolation": "lanczos"
    },
    "_meta": {
      "title": "Resize + Pad Sub"
    }
  }
}
